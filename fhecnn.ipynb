{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQLVKz9oimsG"
      },
      "source": [
        "# <p style=\"padding: 15px; background-color: #778899; font-family: 'JetBrains Mono'; font-weight: bold; font-size: 150%; color: #f2f2f0; letter-spacing: 2px; text-align: center; border-radius: 8px;\">Emotion Recognition Project</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bxFlCBZ1soHO"
      },
      "outputs": [],
      "source": [
        "pip install torch==1.13.1 concrete-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YM24pLUjimsJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import copy\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zmBRWphZimsK",
        "outputId": "8e5a3421-5367-4648-f340-a1b047b66f5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       emotion        Usage                                             pixels\n",
              "0            0     Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1            0     Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2            2     Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3            4     Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4            6     Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
              "...        ...          ...                                                ...\n",
              "35882        6  PrivateTest  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...\n",
              "35883        3  PrivateTest  178 174 172 173 181 188 191 194 196 199 200 20...\n",
              "35884        0  PrivateTest  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...\n",
              "35885        3  PrivateTest  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...\n",
              "35886        2  PrivateTest  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...\n",
              "\n",
              "[35887 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef0369c3-2a00-457f-a8d0-056706e3fad7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>Usage</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Training</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Training</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Training</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35882</th>\n",
              "      <td>6</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35883</th>\n",
              "      <td>3</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35884</th>\n",
              "      <td>0</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35885</th>\n",
              "      <td>3</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35886</th>\n",
              "      <td>2</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35887 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef0369c3-2a00-457f-a8d0-056706e3fad7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef0369c3-2a00-457f-a8d0-056706e3fad7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef0369c3-2a00-457f-a8d0-056706e3fad7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a348d2ac-bf21-46dc-b2d7-036beede71e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a348d2ac-bf21-46dc-b2d7-036beede71e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a348d2ac-bf21-46dc-b2d7-036beede71e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 35887,\n  \"fields\": [\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Usage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Training\",\n          \"PublicTest\",\n          \"PrivateTest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" pixels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 34034,\n        \"samples\": [\n          \"34 40 24 31 27 18 26 21 28 86 131 143 146 143 135 126 141 153 136 132 138 134 131 135 133 134 124 118 109 99 92 87 79 65 59 37 25 30 21 15 10 28 79 79 81 81 80 77 42 29 31 33 21 22 27 19 36 100 129 134 145 151 143 149 166 163 147 154 154 148 146 140 135 134 127 124 114 105 100 93 81 67 57 47 33 25 20 22 15 17 69 76 81 81 81 78 35 32 32 30 25 29 23 24 49 118 118 138 156 157 158 178 182 162 169 168 156 154 147 143 139 134 132 126 119 111 103 100 85 69 59 43 42 26 18 17 15 16 58 80 79 80 81 81 31 34 30 24 30 27 22 25 79 122 131 160 167 175 186 189 181 177 177 168 162 162 152 144 138 137 133 127 123 115 104 99 89 74 59 44 37 34 18 16 14 8 45 80 78 79 80 79 39 30 23 32 37 26 27 36 91 136 174 178 183 187 187 186 187 184 177 172 168 165 157 147 143 142 135 130 123 114 101 98 90 76 62 48 32 33 21 15 15 9 38 73 78 77 77 76 37 28 33 40 30 27 33 49 123 184 187 188 186 188 190 189 188 184 179 173 173 169 160 154 147 145 138 131 127 110 100 97 89 75 61 51 35 28 19 14 15 9 33 65 74 76 76 76 46 40 46 37 27 31 43 70 178 189 188 185 188 190 191 187 188 182 177 176 172 168 161 156 151 144 140 133 129 113 101 95 86 76 63 53 41 24 17 12 16 11 27 65 77 78 75 73 35 38 38 30 34 42 51 125 198 185 190 189 189 191 190 188 185 182 177 177 174 170 165 158 150 143 139 135 126 118 108 97 82 72 64 56 42 28 16 13 15 11 23 68 79 75 72 70 35 40 33 36 39 50 83 167 190 186 190 190 187 187 188 186 186 180 174 178 177 173 168 159 152 146 142 136 131 122 108 99 85 74 63 53 45 39 22 12 14 10 26 66 74 73 71 70 47 40 40 42 45 62 128 186 184 184 183 184 183 178 178 176 180 176 172 173 177 175 169 161 152 145 143 140 133 127 114 102 91 75 64 55 48 42 30 12 14 11 24 63 69 73 70 68 38 45 36 50 43 89 163 188 195 198 196 183 176 177 180 181 179 174 170 168 174 175 170 165 155 145 144 146 139 131 122 109 95 75 64 54 49 46 36 15 13 11 24 64 64 68 66 67 45 43 40 59 48 134 186 170 147 128 117 102 103 96 88 112 148 158 149 152 161 171 169 167 158 147 147 148 145 135 131 124 105 83 68 58 54 49 42 15 12 14 17 63 62 63 64 67 54 30 65 53 78 182 179 158 152 162 177 193 195 166 118 61 48 60 84 101 138 163 170 166 161 152 148 149 147 144 143 134 112 82 58 47 43 46 51 14 12 14 13 58 64 62 65 68 47 32 77 46 136 191 185 199 207 208 206 201 198 203 200 183 141 97 95 105 136 158 172 172 171 160 152 148 153 147 135 106 73 32 15 16 23 25 36 15 11 14 17 50 65 63 67 69 28 42 61 65 181 191 193 193 192 191 193 198 195 158 135 122 140 166 164 158 167 179 181 184 173 162 153 151 153 141 110 92 56 53 76 77 66 49 40 16 11 16 22 47 66 64 68 68 27 49 39 120 195 193 197 193 190 184 179 150 77 72 73 83 63 84 141 168 179 194 199 197 185 169 147 143 145 150 155 137 133 141 129 121 89 55 60 18 11 17 22 43 66 66 68 67 37 32 45 172 194 194 201 196 187 187 134 122 137 132 78 120 132 92 121 160 157 194 208 211 197 173 133 95 86 94 65 63 73 44 46 47 51 56 58 17 12 17 24 36 67 66 68 65 44 12 77 193 186 195 196 196 193 184 162 163 161 120 125 144 169 93 76 165 168 197 205 214 199 164 97 46 42 33 63 47 83 81 60 42 52 49 59 16 12 17 24 29 65 65 66 65 46 8 105 194 188 193 188 185 183 183 189 185 165 139 122 128 107 90 100 150 186 191 196 207 193 147 68 41 34 48 56 60 65 103 60 29 52 57 59 14 13 19 25 24 58 64 64 64 43 7 124 192 185 190 186 180 179 181 188 201 199 183 166 139 133 127 132 134 168 179 191 196 181 135 63 38 43 53 71 66 72 67 54 52 46 61 58 10 15 20 24 22 55 64 62 61 37 8 133 191 185 192 187 181 177 178 180 188 189 182 170 154 138 132 131 147 161 170 187 190 174 130 70 39 37 45 62 83 89 78 74 60 63 68 53 8 16 20 22 22 56 65 60 60 32 8 137 188 189 195 193 191 184 176 174 173 169 169 163 154 151 150 152 162 166 170 183 186 176 136 77 47 46 44 50 62 78 80 68 65 67 74 50 8 16 20 23 20 51 62 58 57 33 6 137 192 190 199 201 200 192 180 171 166 163 161 158 155 155 157 161 170 171 173 182 186 176 146 100 76 63 56 55 61 67 70 72 77 75 77 42 7 17 19 25 18 43 65 59 56 34 10 137 192 190 200 203 199 194 188 179 171 166 160 160 158 160 164 166 172 172 174 179 183 175 143 103 90 87 81 71 64 70 76 78 81 78 75 32 8 20 18 23 18 30 67 64 58 30 11 132 192 189 193 196 195 195 194 188 178 170 164 163 162 163 167 172 179 181 176 176 179 168 144 109 91 88 90 92 85 73 73 77 77 73 71 21 11 19 18 23 18 20 57 58 54 32 6 132 190 184 190 193 194 195 193 188 183 177 169 166 164 166 171 179 192 189 177 175 175 164 145 119 97 88 88 92 95 93 78 70 70 68 63 12 14 19 16 24 20 15 45 48 42 29 16 131 185 185 191 191 194 195 194 192 186 180 174 169 170 168 172 181 189 179 176 174 173 163 146 125 100 82 86 89 92 94 97 81 60 64 48 7 16 20 15 22 24 14 33 46 40 48 47 133 184 185 191 191 192 196 196 194 192 185 177 172 168 167 169 179 174 161 169 178 179 166 152 130 97 71 82 90 99 104 104 97 72 60 30 9 17 20 17 22 25 15 24 40 42 65 48 131 183 184 190 191 193 195 197 195 192 187 179 173 166 164 165 179 178 176 181 193 193 172 163 137 92 74 86 106 118 115 109 97 87 70 13 13 17 20 18 20 27 18 19 30 36 62 44 122 182 183 190 192 194 197 197 196 195 192 184 173 164 162 166 185 200 193 190 193 197 180 167 119 88 92 114 135 133 120 109 93 85 75 24 12 18 20 15 19 24 21 19 23 27 62 44 111 184 179 188 191 193 195 200 201 201 197 186 173 166 167 176 177 176 167 179 195 187 182 145 108 122 89 121 140 137 124 108 90 83 61 50 22 17 18 15 18 19 21 21 19 22 65 47 103 180 181 188 192 193 199 205 205 200 196 187 175 171 176 180 179 171 176 187 195 187 142 59 41 55 65 100 129 134 126 106 87 78 50 53 47 18 16 15 18 17 23 27 16 34 68 47 96 173 183 188 193 200 204 205 204 202 195 187 180 180 180 182 184 182 181 180 179 163 132 69 53 58 60 71 104 126 123 100 84 68 47 53 57 37 12 14 19 16 22 33 17 36 70 48 82 166 181 192 197 203 204 204 203 200 195 192 188 185 186 188 187 184 182 176 151 156 164 95 58 55 58 63 77 104 116 92 83 55 50 54 54 54 20 13 18 17 18 33 24 21 64 56 60 154 181 196 198 201 203 203 203 201 198 196 190 184 185 186 187 184 178 172 138 136 155 90 56 54 54 62 74 80 95 87 74 48 53 54 54 56 40 13 17 18 17 26 29 18 66 56 50 129 184 191 197 197 200 201 203 202 198 190 187 187 192 196 191 187 180 172 156 136 130 102 64 52 60 76 77 83 69 69 63 49 54 54 54 53 53 26 14 21 20 19 34 20 68 56 48 69 186 188 195 196 197 201 201 197 191 188 171 129 137 146 141 140 134 140 132 117 102 112 113 64 92 112 84 82 60 41 33 56 53 55 54 53 54 42 15 20 20 16 31 24 66 56 37 15 147 198 192 198 198 198 194 192 189 185 173 170 145 130 137 133 116 102 94 100 72 61 58 65 104 112 95 72 54 20 11 45 56 54 54 52 52 53 24 16 19 16 29 29 68 50 28 9 59 201 189 198 200 194 193 190 189 186 184 189 196 184 175 170 153 128 109 119 90 68 65 78 105 118 92 61 33 9 14 21 53 54 54 52 51 56 38 16 24 18 25 32 67 32 25 25 6 128 210 191 194 193 194 191 190 188 187 184 187 191 190 178 161 146 130 121 102 83 81 87 95 110 91 40 9 17 17 14 32 56 53 52 52 54 52 20 20 22 21 33 58 21 29 22 23 17 161 204 188 194 194 194 194 192 190 187 186 184 181 173 160 159 155 154 136 109 87 86 88 93 79 29 15 19 15 17 15 47 53 52 53 53 57 30 18 24 23 32 45 18 29 23 27 19 34 170 201 188 192 194 194 193 191 190 191 185 178 163 158 152 156 154 133 110 88 82 87 77 50 56 28 14 17 16 12 30 54 52 53 53 57 41 18 23 24 32 33 20 28 26 24 27 47 60 154 204 187 192 195 194 199 202 194 186 176 165 163 144 132 126 116 96 79 83 75 49 55 60 48 12 21 18 16 17 48 52 53 54 58 49 19 24 22 30 27 17 33 29 24 32 65 64 58 132 199 193 189 200 206 204 199 190 176 169 161 146 124 102 76 67 83 73 50 56 58 57 57 28 20 20 15 12 36 54 52 54 57 56 22 22 21 24 27 16 35 28 21 46 66 65 73 64 109 180 198 198 200 202 204 197 186 174 164 154 133 101 60 49 58 55 53 63 57 59 56 47 20 17 16 12 25 53 53 55 57 58 27 19 23 18 30 18 28 33 20 52 66 68 73 83 81 100 152 197 203 201 197 194 185 170 162 157 139 104 67 44 19 47 55 60 53 58 56 57 27 13 18 14 18 48 52 56 56 59 33 18 22 21 32 16 26 33 24 55 65 66 70 75 90 92 86 123 159 181 187 186 178 168 167 160 139 97 53 42 27 25 50 59 54 57 57 60 36 12 21 14 15 45 54 55 55 61 39 19 22 21 37 16 23 29 30 64 69 66 68 72 83 79 82 93 100 111 121 122 122 129 136 131 113 55 55 51 32 18 38 60 57 59 60 62 44 15 20 15 13 41 55 56 57 59 42 18 24 18\",\n          \"30 31 31 31 31 31 32 32 32 34 41 46 35 60 70 51 58 110 101 77 60 53 51 42 43 47 38 26 19 14 14 14 17 21 20 20 17 20 21 26 35 35 34 33 31 29 27 27 30 31 31 31 31 31 32 32 33 38 46 36 49 63 55 60 113 103 74 72 63 53 44 43 41 32 24 19 16 13 11 12 13 15 19 21 20 20 19 20 29 36 35 33 31 29 28 28 30 31 31 31 31 32 33 34 35 40 40 34 39 50 56 116 97 65 59 50 43 35 33 40 30 16 14 15 16 15 11 9 10 12 16 17 20 19 18 16 17 31 36 34 32 30 28 28 30 31 31 31 32 32 35 36 42 37 29 24 39 53 96 108 66 76 76 64 53 52 45 35 23 13 8 4 2 3 9 11 12 11 14 17 18 20 19 21 15 17 37 35 33 30 28 28 30 31 31 31 31 32 36 38 42 23 17 16 30 65 137 141 155 158 148 145 145 149 144 129 118 112 100 83 68 41 7 3 10 13 13 14 17 18 21 24 24 15 24 37 33 30 29 28 30 31 31 31 31 32 33 41 30 13 7 9 53 134 181 192 201 199 192 192 192 194 194 185 178 173 165 155 141 125 89 39 8 6 12 12 15 17 17 21 28 19 10 33 35 31 29 28 30 31 31 31 31 33 35 42 24 14 10 69 154 193 204 206 207 206 202 200 200 198 194 189 185 172 159 153 144 132 127 118 75 26 10 11 11 16 17 15 24 29 9 20 36 32 29 28 30 30 31 32 32 33 43 36 25 10 43 154 195 196 201 207 208 208 206 202 202 200 196 192 187 175 164 155 149 141 134 131 120 85 37 14 14 14 18 18 15 25 17 6 30 33 29 28 30 30 32 32 32 33 43 34 19 8 112 188 191 198 203 207 207 206 204 202 201 200 196 193 188 180 170 163 153 143 139 138 126 104 73 28 16 15 14 16 19 18 19 1 17 32 29 28 30 30 31 32 31 33 46 27 8 37 167 189 193 199 206 208 206 203 203 202 200 199 197 193 188 180 172 166 156 148 143 139 127 113 89 43 18 14 16 14 21 24 10 0 6 28 31 28 30 31 31 31 32 36 44 20 6 78 184 189 194 200 206 207 205 203 202 201 202 201 197 191 187 182 175 168 159 149 143 138 125 114 104 72 35 14 15 17 16 23 9 0 1 20 32 28 30 31 31 32 32 39 40 12 7 97 185 189 196 201 205 208 207 204 204 204 204 204 199 193 190 185 178 171 163 153 144 136 126 114 104 97 76 36 14 16 17 21 19 19 8 14 32 28 30 30 31 32 32 40 43 10 11 97 185 189 195 200 204 207 210 210 207 206 206 205 201 194 188 185 182 176 171 159 147 142 131 113 104 98 89 69 29 16 20 21 23 60 43 8 30 29 30 30 31 31 31 41 49 8 11 94 184 190 195 199 203 208 212 213 208 207 207 207 204 195 187 183 174 156 137 115 105 111 116 117 108 100 93 80 47 16 20 22 24 33 43 18 26 31 30 31 31 32 30 49 62 8 8 85 180 189 194 198 205 208 210 211 207 206 206 204 199 193 167 133 95 73 73 79 85 83 79 85 100 102 96 87 60 21 18 20 22 26 48 38 25 33 30 31 31 32 31 49 71 9 6 76 174 188 192 200 208 213 213 209 205 203 203 196 190 179 127 81 72 85 104 118 113 106 98 85 90 102 99 93 77 29 16 18 19 24 37 43 28 37 30 30 30 32 29 48 79 11 6 59 165 185 195 205 203 192 177 186 198 195 196 188 177 153 105 81 72 64 68 59 48 46 57 83 93 98 100 97 89 46 19 17 19 18 32 45 22 39 30 31 31 32 30 52 77 19 7 42 154 187 172 143 123 97 95 123 168 186 190 183 163 119 85 72 53 79 89 25 45 68 30 55 97 110 109 101 94 72 32 22 17 17 23 43 13 34 31 31 31 32 32 57 80 29 1 18 148 163 105 109 116 115 108 112 134 169 193 192 161 102 81 77 66 162 126 55 77 86 70 89 123 134 122 106 97 90 62 29 22 14 17 29 10 24 30 31 31 33 33 56 77 31 0 7 126 127 142 169 136 91 70 67 80 140 193 198 162 106 95 115 122 150 149 131 117 112 121 144 153 143 127 109 98 91 83 45 27 13 20 20 7 16 30 30 31 32 33 53 71 33 8 16 97 147 165 113 58 86 76 38 82 129 190 196 164 118 115 133 154 149 144 143 139 145 160 165 157 139 123 111 99 90 88 60 29 14 23 24 10 14 30 30 30 31 33 53 63 35 9 19 94 170 139 44 111 163 66 75 132 165 194 194 166 130 121 131 146 157 160 164 172 180 181 171 153 135 121 110 99 89 85 66 31 19 26 31 13 13 30 30 30 31 32 59 64 35 9 19 88 173 151 87 122 151 144 155 149 183 199 196 167 136 125 126 145 162 174 182 183 182 178 165 149 133 120 108 100 87 84 66 30 30 29 40 19 12 30 30 30 32 34 61 65 40 15 13 81 168 180 169 163 163 153 146 177 190 196 200 165 134 120 120 142 163 167 177 183 182 176 162 145 130 116 106 100 87 83 63 34 38 29 38 25 10 30 30 30 32 35 63 66 41 21 6 62 168 190 190 186 179 177 194 204 187 192 203 175 145 120 114 127 146 162 171 175 177 172 160 142 127 111 102 99 88 83 59 36 36 28 32 23 7 30 30 31 32 37 68 70 38 25 11 46 164 184 194 201 203 205 207 199 186 191 204 189 159 123 117 130 118 132 154 162 167 164 152 136 119 106 98 97 91 84 50 11 28 23 27 19 9 30 30 31 33 38 67 64 41 26 17 30 147 177 188 198 204 208 205 197 184 189 206 196 165 131 123 134 101 88 123 144 154 153 141 126 113 101 96 95 93 80 61 20 22 20 24 18 9 30 30 31 31 38 67 63 45 26 14 7 105 174 179 190 198 203 199 182 175 188 196 185 145 102 89 77 72 77 98 117 134 138 130 119 103 94 93 92 93 77 65 43 21 20 22 15 5 30 30 30 32 39 66 60 46 28 12 1 56 163 174 185 189 193 185 151 154 160 148 149 105 75 65 68 81 87 95 103 106 117 119 108 95 89 90 89 93 79 38 27 30 19 19 15 8 30 30 30 30 39 71 58 47 27 10 5 17 136 171 178 183 180 164 129 154 149 108 110 86 71 79 87 92 100 101 103 109 111 116 112 97 91 86 89 95 74 39 11 30 22 16 12 9 30 30 30 30 45 71 56 43 27 7 6 2 77 164 167 171 167 144 124 168 185 171 155 140 119 117 113 114 117 108 98 88 103 130 127 106 90 84 90 93 66 40 13 26 23 16 13 8 30 31 31 30 47 68 54 41 24 6 5 2 61 153 158 160 153 127 118 171 182 185 194 192 180 159 110 84 74 72 53 41 105 135 133 102 84 86 90 88 57 41 12 26 25 15 12 7 30 31 30 29 47 66 51 42 23 5 7 7 85 118 153 148 143 110 124 184 190 182 155 132 120 88 86 106 115 98 71 101 127 125 130 98 84 88 88 80 46 42 10 21 26 15 12 8 31 30 30 30 49 63 50 40 23 3 7 10 76 64 138 146 144 111 142 156 122 95 123 143 156 167 205 172 138 108 108 120 118 123 128 97 87 87 84 65 44 44 7 25 29 13 14 10 31 31 31 32 51 58 49 38 21 3 11 10 56 46 107 151 147 132 148 145 78 78 188 207 215 185 159 124 130 115 103 108 116 122 120 94 88 84 79 49 47 36 5 24 33 13 15 10 31 32 31 35 48 50 46 30 16 5 13 18 27 33 63 144 142 143 153 186 181 152 153 162 169 150 147 145 106 87 95 109 114 116 106 91 87 79 66 38 53 31 6 22 32 18 16 10 31 31 31 35 48 48 39 23 14 5 15 22 24 35 25 117 141 139 151 176 180 155 151 176 168 152 137 105 78 88 101 108 112 111 97 85 79 73 45 43 53 23 6 25 32 22 19 10 31 31 31 35 44 41 40 22 15 7 21 28 24 37 24 55 141 137 151 166 174 167 143 128 124 111 87 79 89 101 104 114 116 100 87 76 71 59 31 55 43 14 6 26 36 22 21 14 31 31 29 37 43 40 38 18 13 11 25 30 27 34 33 7 82 145 145 161 165 167 157 136 116 107 97 110 118 118 124 127 111 92 78 69 65 35 41 53 29 8 8 27 35 26 19 15 31 31 30 38 43 39 38 19 15 14 29 31 29 29 32 14 7 105 144 149 162 163 158 152 149 149 147 150 147 140 137 126 99 80 67 62 41 26 53 43 21 9 11 28 36 29 18 13 30 31 31 37 39 34 43 19 13 18 37 31 27 25 32 16 2 22 115 143 153 165 165 163 168 172 170 164 156 143 130 107 81 64 57 45 22 46 49 34 17 8 12 30 42 32 19 15 30 30 31 38 36 28 44 22 14 18 42 35 26 21 29 12 6 5 38 109 136 152 165 170 174 172 162 153 144 132 107 80 59 51 42 23 38 51 42 29 16 6 15 29 39 36 22 18 30 30 29 39 33 30 46 26 16 18 45 40 26 16 26 12 6 6 12 38 92 125 146 162 164 157 139 126 125 102 73 56 46 36 25 39 49 46 39 27 14 10 21 28 40 36 21 20 30 30 31 39 34 29 48 33 16 19 45 37 28 14 26 10 11 4 6 26 34 65 102 118 129 126 110 104 91 65 47 37 31 29 43 49 49 47 39 28 12 13 21 26 44 36 23 22 30 30 29 36 33 32 47 31 19 17 44 37 31 15 24 10 8 5 14 34 30 31 61 111 92 77 67 60 48 37 27 27 39 53 51 47 49 50 36 27 11 15 20 27 46 35 24 26 30 30 29 34 36 36 43 30 18 17 44 39 30 14 26 15 11 2 27 36 47 33 23 95 138 102 80 59 44 35 39 56 62 57 49 47 57 51 36 25 11 19 24 27 43 33 26 28 29 29 32 37 35 36 42 24 15 17 47 40 30 15 25 14 14 9 24 26 48 38 17 49 129 131 110 98 86 83 82 77 69 60 56 60 62 49 37 17 16 22 26 28 46 33 24 29 29 28 31 39 35 41 40 22 17 16 44 41 30 18 25 12 10 16 22 27 43 42 23 41 110 140 127 116 111 105 96 88 78 70 71 67 61 52 34 19 22 21 25 33 48 34 25 30\",\n          \"172 170 169 140 56 27 43 49 40 22 29 30 30 46 55 88 115 129 135 134 144 143 138 137 148 165 160 145 148 141 136 139 123 97 89 73 47 28 20 26 16 13 13 14 14 12 10 10 172 170 166 109 43 34 36 35 18 22 14 21 42 65 98 120 132 138 137 144 153 161 162 157 164 167 163 160 152 150 145 149 137 118 107 85 62 51 31 31 21 11 12 9 11 14 12 11 170 168 154 74 36 37 34 23 20 13 21 37 59 100 123 134 139 143 149 154 160 170 175 174 175 170 169 168 160 159 154 152 146 133 117 107 90 66 53 37 24 22 15 10 9 10 12 12 167 167 123 52 43 42 29 20 10 17 32 58 87 112 129 138 147 158 161 167 174 180 183 182 182 180 170 168 168 169 166 159 146 140 127 115 105 101 88 64 49 37 17 12 11 11 12 12 165 157 87 44 56 35 20 14 11 24 51 76 98 118 134 144 159 165 163 175 182 184 184 186 189 183 173 175 175 175 170 163 156 141 135 118 112 110 96 91 76 56 48 26 16 11 9 10 168 129 55 51 63 27 14 8 14 34 60 89 107 128 142 155 165 169 173 183 193 193 192 192 194 190 187 180 179 177 174 172 159 139 133 113 117 119 115 103 83 66 55 41 23 10 11 11 159 90 45 54 52 22 10 10 23 55 75 95 122 137 148 157 169 175 185 187 189 187 192 197 194 195 192 192 190 185 178 173 163 146 134 133 131 121 109 110 100 85 66 38 31 23 12 12 121 66 49 57 43 18 10 11 43 79 94 107 122 133 147 162 173 175 181 188 185 189 196 197 196 196 192 190 188 186 182 175 167 153 143 143 130 129 127 119 111 96 82 58 34 27 13 13 91 47 49 53 36 12 12 17 56 82 102 114 125 139 149 163 175 174 177 186 187 191 195 194 194 193 188 185 185 185 182 175 167 153 148 148 144 137 138 129 126 115 89 62 42 26 19 15 81 48 52 38 29 13 10 16 54 93 112 114 127 135 147 164 178 177 175 186 185 189 194 195 198 195 190 190 184 183 182 175 169 161 150 145 147 142 135 134 135 124 100 65 45 32 24 12 62 51 46 31 19 14 10 13 68 109 114 120 128 140 147 161 172 173 177 186 183 189 190 195 196 194 193 192 183 178 185 174 165 163 159 153 145 142 138 134 129 118 106 84 41 33 26 11 52 49 42 27 14 12 9 12 74 107 117 126 144 158 161 170 178 172 181 195 191 188 192 197 189 191 196 197 180 178 184 173 168 163 163 163 152 148 142 134 125 112 100 87 70 55 33 17 51 49 36 20 13 10 9 16 74 113 125 130 150 164 181 189 184 178 191 196 193 191 194 199 195 191 198 207 189 173 186 176 176 174 174 168 159 154 143 132 122 115 100 92 84 73 35 18 58 50 36 16 14 10 9 16 86 114 110 112 104 121 131 137 144 168 182 177 173 188 192 197 190 176 180 187 185 179 174 165 157 148 143 153 145 131 129 122 121 116 108 99 95 88 53 27 53 43 33 22 12 13 7 25 93 107 128 132 136 113 92 84 91 115 151 144 143 177 191 194 184 160 146 148 141 129 118 106 104 112 128 144 141 138 127 119 119 119 115 106 97 96 78 37 47 35 33 23 10 14 5 38 106 122 138 154 168 166 159 129 105 102 120 128 139 170 186 184 175 154 137 127 103 90 88 95 127 159 168 164 161 153 140 132 128 114 116 113 104 101 98 53 41 35 31 13 11 13 5 59 117 118 130 147 145 155 161 157 140 127 124 129 131 158 189 191 172 150 135 132 120 122 141 163 180 177 163 162 159 148 134 128 125 128 125 123 112 99 98 133 39 36 22 14 12 12 10 79 119 114 103 101 124 150 147 138 126 128 134 131 133 149 189 195 174 159 147 141 128 126 125 135 154 155 144 140 140 130 127 118 111 119 128 129 116 87 153 196 37 35 24 14 11 10 18 97 121 111 92 111 118 131 142 138 124 130 131 140 140 152 184 191 178 164 147 133 112 109 83 101 139 151 150 153 152 130 112 99 102 113 132 129 139 101 183 187 40 31 22 14 11 6 32 116 134 111 66 29 9 39 157 166 155 132 120 137 148 158 181 189 179 161 148 122 113 99 85 38 51 68 149 131 113 103 94 87 92 105 136 178 181 102 179 195 40 27 19 14 11 4 46 133 145 104 58 62 62 60 206 216 180 146 137 142 157 166 182 188 179 163 154 141 112 105 138 88 67 107 170 120 74 51 65 97 129 119 177 198 159 80 160 195 41 26 23 12 12 4 59 139 145 137 145 107 94 113 133 143 152 154 163 167 164 167 181 183 177 168 167 163 145 131 130 144 146 137 130 144 148 136 137 147 153 127 191 200 170 77 134 200 53 27 12 10 12 4 71 145 149 163 155 138 125 127 134 144 148 165 184 174 167 166 180 179 167 161 170 171 177 167 141 133 140 137 146 152 157 160 162 167 161 129 196 200 169 94 124 208 57 21 11 10 12 5 92 147 157 164 164 159 156 153 155 160 183 200 183 169 159 167 176 174 162 150 157 170 178 192 195 185 172 165 166 171 173 182 178 178 165 145 211 201 185 106 97 202 59 16 10 11 10 7 100 151 163 169 172 170 167 169 177 188 200 195 177 161 160 167 171 173 166 153 145 169 173 191 201 203 202 198 198 197 193 192 185 182 160 167 216 199 187 117 71 188 47 12 11 11 11 9 101 152 169 180 181 184 187 193 198 197 203 199 172 158 174 179 183 185 174 152 131 149 181 196 206 207 209 206 204 203 199 190 183 182 148 171 212 187 169 103 72 177 39 12 11 11 11 7 101 153 166 177 182 190 195 203 208 213 212 194 156 162 190 216 209 200 186 154 142 134 146 206 216 219 216 211 208 203 200 196 190 175 154 208 203 171 136 98 129 194 32 13 11 11 11 3 89 156 159 173 182 193 201 207 220 219 203 170 170 176 187 205 200 186 188 187 188 176 134 148 213 220 218 215 207 202 200 201 193 159 188 209 192 167 120 94 152 210 32 12 11 11 12 2 67 154 158 172 185 196 206 214 216 209 179 178 187 167 160 171 176 165 161 180 184 191 167 111 182 215 216 216 210 206 202 200 174 172 219 205 187 166 127 93 189 215 28 12 11 10 13 4 45 144 157 171 184 194 203 209 206 193 176 167 118 83 85 143 153 129 110 77 80 150 172 112 176 216 216 216 206 204 201 183 161 202 220 209 193 165 108 105 197 203 27 12 10 9 12 3 25 134 155 171 184 191 202 206 202 189 190 162 146 162 174 193 162 177 191 181 182 165 138 135 196 211 213 211 203 198 178 162 201 217 214 207 187 164 116 160 199 188 29 11 10 12 6 24 45 111 157 166 179 192 196 200 197 193 186 171 156 147 172 206 186 191 184 167 157 151 156 181 192 203 212 204 196 178 157 200 218 213 208 195 178 150 117 192 197 176 26 9 11 9 14 76 11 77 155 159 175 184 191 193 192 188 180 171 162 155 167 185 172 178 172 158 165 176 184 188 191 193 199 192 180 152 197 224 221 211 204 183 170 152 123 170 179 160 26 11 15 2 60 41 0 46 140 155 166 179 184 184 179 180 166 160 149 147 156 159 158 164 161 162 166 175 180 185 187 185 187 172 144 168 210 222 217 208 199 174 168 162 150 155 160 147 26 11 14 13 71 11 9 20 123 151 160 169 175 167 164 164 141 144 146 157 172 168 185 180 164 162 158 158 165 169 168 165 159 140 179 218 218 216 212 205 182 164 166 161 156 151 145 144 21 12 11 26 69 3 13 7 94 142 155 166 166 156 157 139 138 140 147 173 184 198 209 197 194 186 175 167 160 153 135 121 106 170 223 220 222 216 210 199 169 161 168 162 155 142 135 147 20 10 14 29 67 6 13 3 71 136 144 159 160 151 138 119 130 133 140 144 157 172 162 162 158 147 143 142 142 129 106 58 138 220 221 223 217 213 213 195 169 166 177 162 145 124 139 140 18 10 14 16 52 15 10 5 47 128 132 147 156 153 131 106 99 124 132 137 131 130 135 132 132 134 132 141 125 93 56 103 216 219 221 221 216 210 203 189 171 169 169 155 134 131 152 139 17 11 16 19 33 33 7 10 25 109 128 138 154 158 130 95 119 148 164 168 174 173 179 186 184 195 184 155 137 104 102 207 219 223 224 218 215 203 192 181 172 166 159 151 139 152 148 125 20 11 14 24 18 31 17 12 10 73 134 129 144 159 142 118 119 130 153 172 191 195 198 212 192 184 155 133 117 74 173 222 221 221 222 216 209 197 187 174 168 161 157 149 145 149 133 100 20 13 11 20 25 15 16 10 16 41 119 129 133 147 147 139 126 119 125 147 160 166 159 166 152 133 119 106 77 138 226 218 225 224 218 215 200 188 180 171 165 159 152 146 147 136 113 110 16 15 14 13 20 19 14 10 19 13 69 131 122 136 140 144 129 120 122 133 135 135 133 128 122 118 114 107 127 213 222 226 227 223 216 209 196 184 176 166 160 155 145 138 139 123 116 129 24 15 16 13 14 19 11 13 15 10 23 109 120 127 136 139 130 126 133 136 130 127 133 131 135 142 136 119 182 227 226 228 223 218 214 207 190 178 171 164 153 151 142 135 127 119 127 130 47 24 22 20 15 18 17 13 15 20 6 50 121 118 129 135 132 131 133 136 138 139 150 154 163 164 144 164 220 222 229 226 220 214 210 203 187 175 166 154 151 149 134 126 123 128 127 115 64 50 33 24 21 22 25 25 26 18 13 5 81 125 121 137 135 136 139 146 150 159 166 171 174 171 157 204 226 224 224 219 213 214 208 194 183 173 161 149 148 141 129 121 120 126 115 91 66 65 57 42 28 25 28 29 30 22 13 7 14 98 124 134 137 135 141 153 160 162 165 168 179 178 174 212 224 227 225 218 216 210 205 195 180 169 159 147 141 131 121 115 118 117 103 57 68 69 67 59 43 33 29 29 33 32 21 10 5 26 100 122 134 138 141 150 158 163 161 157 173 176 183 214 218 219 220 215 211 207 200 190 176 165 153 142 132 123 115 113 114 108 82 15 73 67 67 65 57 47 37 34 39 38 34 13 9 19 57 98 116 133 137 141 150 158 158 154 163 162 180 217 213 213 212 215 212 204 192 178 168 158 147 135 121 113 113 112 108 105 53 11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "data = pd.read_csv(\n",
        "        \"icml_face_data.csv\"\n",
        "    )\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mzp-SKkimsK",
        "outputId": "4ff23bf7-43e1-4596-99a1-292502f7dd41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35887 entries, 0 to 35886\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   emotion  35887 non-null  int64 \n",
            " 1    Usage   35887 non-null  object\n",
            " 2    pixels  35887 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 841.2+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IlPFEooVimsL"
      },
      "outputs": [],
      "source": [
        "emotions = {\n",
        "    0: \"Angry\",\n",
        "    1: \"Disgust\",\n",
        "    2: \"Fear\",\n",
        "    3: \"Happy\",\n",
        "    4: \"Sad\",\n",
        "    5: \"Surprise\",\n",
        "    6: \"Neutral\",\n",
        "}\n",
        "class_percentages = {}\n",
        "num_labels = 7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision==0.17.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_MaKVBERE82",
        "outputId": "ba599ae8-bd38-44c7-c2c3-59e8f1588a62"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision==0.17.2 in /usr/local/lib/python3.10/dist-packages (0.17.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.2) (1.23.5)\n",
            "Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.2) (2.2.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.2) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchvision==0.17.2) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchvision==0.17.2) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2->torchvision==0.17.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2->torchvision==0.17.2) (1.3.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 856, in _parseNoCache\n",
            "    tokens = fn(instring, tokens_start, ret_tokens)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 291, in wrapper\n",
            "    ret = func(*args[limit:])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 71, in <lambda>\n",
            "    lambda s, l, t: Marker(s[t._original_start : t._original_end])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 278, in __init__\n",
            "    self._markers = _coerce_parse_result(MARKER.parseString(marker))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5226, in parseImpl\n",
            "    return super().parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 815, in _parseNoCache\n",
            "    if self.mayIndexError or pre_loc >= len_instring:\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "54RU6AdXimsL"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def prepare_data(data, size=(12, 12)):\n",
        "    \"\"\"Prepare data for modeling.\n",
        "    Input:\n",
        "        data - DataFrame with labels and pixel data.\n",
        "        size - New size of the images (tuple).\n",
        "    Output:\n",
        "        image and label tensors.\"\"\"\n",
        "\n",
        "    resize_transform = transforms.Resize(size)\n",
        "\n",
        "    image_array = np.zeros(shape=(len(data), size[0], size[1]))\n",
        "    image_label = np.array(list(map(int, data[\"emotion\"])))\n",
        "\n",
        "    for i, row in enumerate(data.index):\n",
        "        image = np.fromstring(data.loc[row, \" pixels\"], dtype=int, sep=\" \")\n",
        "        image = np.reshape(image, (48, 48))\n",
        "        image = torch.tensor(image).unsqueeze(0).unsqueeze(0).float()  # Convert to tensor, add batch and channel dimensions\n",
        "        image = resize_transform(image)  # Apply resizing\n",
        "        image_array[i] = image.squeeze().numpy()  # Remove dimensions and convert back to numpy\n",
        "\n",
        "    image_array = torch.from_numpy(image_array)\n",
        "    image_label = torch.from_numpy(image_label)\n",
        "\n",
        "    return image_array.float(), image_label\n",
        "\n",
        "# Example usage for 6x6 image size:\n",
        "df_train_array, df_train_label = prepare_data(data[data[\" Usage\"] == \"Training\"], (6, 6))\n",
        "df_val_array, df_val_label = prepare_data(data[data[\" Usage\"] == \"PublicTest\"], (6, 6))\n",
        "df_test_array, df_test_label = prepare_data(data[data[\" Usage\"] == \"PrivateTest\"], (6, 6))\n",
        "\n",
        "train_images = df_train_array.unsqueeze(1) / 255  # Add channel dimension and normalize\n",
        "val_images = df_val_array.unsqueeze(1) / 255\n",
        "test_images = df_test_array.unsqueeze(1) / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1VQpItQimsM"
      },
      "source": [
        "# <p style=\"padding: 15px; background-color: #778899; font-family: 'JetBrains Mono'; font-weight: bold; font-size: 125%; color: #f2f2f0; letter-spacing: 2px; text-align: center; border-radius: 8px;\">Model Selection</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LyNPOajnppi-"
      },
      "outputs": [],
      "source": [
        "def to_categorical_torch(y, num_classes):\n",
        "    return torch.eye(num_classes)[y]\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function to process data batches.\"\"\"\n",
        "    inputs, targets = zip(*batch)\n",
        "    return torch.stack(inputs), torch.stack(targets)\n",
        "\n",
        "\n",
        "train_labels = to_categorical_torch(df_train_label, 7)\n",
        "val_labels = to_categorical_torch(df_val_label, 7)\n",
        "test_labels = to_categorical_torch(df_test_label, 7)\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(train_images, train_labels)\n",
        "val_dataset = TensorDataset(val_images, val_labels)\n",
        "test_dataset = TensorDataset(test_images, test_labels)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43Dkzhi8AM5D",
        "outputId": "a93a2fad-309a-4b31-8782-47e5f6ae408a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compilation successful\n"
          ]
        }
      ],
      "source": [
        "from concrete.ml.torch.compile import compile_torch_model\n",
        "import gc\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, stride=1, padding=0)  # Output size: 10x10\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3, stride=1, padding=0)  # Output size: 8x8\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Output size: 4x4\n",
        "        self.fc1 = nn.Linear( 4 * 4, n_classes)  # Flattened size: 16*4*4\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.flatten(1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# Clear unused memory\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Model instantiation and pruning\n",
        "model = CNN(7)\n",
        "\n",
        "try:\n",
        "    q_module = compile_torch_model(model, train_images, rounding_threshold_bits=6, p_error=0.1)\n",
        "    print(\"Model compilation successful\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"Compilation failed: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_uQpDUgimsM"
      },
      "source": [
        "### Device configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3bdaU9uebzrZ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def test_with_concrete(quantized_module, test_loader, use_sim):\n",
        "    \"\"\"Test a neural network that is quantized and compiled with Concrete ML.\"\"\"\n",
        "    all_y_pred = []\n",
        "\n",
        "    fhe_mode = \"simulate\" if use_sim else \"execute\"\n",
        "\n",
        "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "        data = batch\n",
        "        if isinstance(batch, (list, tuple)) and len(batch) == 2:\n",
        "            data = batch[0]  # Handles cases where data and targets are returned\n",
        "\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            data = data.numpy()  # Ensure conversion to numpy for compatibility with FHE\n",
        "\n",
        "        y_pred = quantized_module.forward(data, fhe=fhe_mode)\n",
        "        y_pred = np.argmax(y_pred, axis=1)  # Assuming classification task\n",
        "        all_y_pred.extend(y_pred)\n",
        "\n",
        "    return np.array(all_y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc-BdqTHdkWt",
        "outputId": "efe8b266-ea72-4186-c8b9-a1ebe8c261f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [00:41<00:00,  1.36it/s]\n"
          ]
        }
      ],
      "source": [
        "q_module.fhe_circuit.keygen()\n",
        "\n",
        "accuracy_test = test_with_concrete(\n",
        "    q_module,\n",
        "    test_loader,\n",
        "    use_sim=True  # Ensure your model and system support running without simulation\n",
        ")\n",
        "\n",
        "accuracy_percentage = 100 * accuracy_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4th7g-cUmmQm",
        "outputId": "df3a019d-20d2-4e50-de38-e91ea07e842e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "accuracy_scalar = accuracy_percentage[0]  # or accuracy_percentage[0]\n",
        "print(f\"Accuracy: {accuracy_scalar:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 31151,
          "sourceId": 3364,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30648,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
